import os
import re
from collections import defaultdict

PROCESSED_DIR = "processed"
OUTPUT_FILE = "trend_analysis.md"

# 1. Broad Categories (Data Structure)
CATEGORIES = {
    "1. é™£åˆ—èˆ‡éˆçµä¸²åˆ— (Arrays & Linked Lists)": [
        "Array", "é™£åˆ—", "Linked List", "éˆçµä¸²åˆ—", "éˆè¡¨", "Sparse Matrix", "ç¨€ç–çŸ©é™£"
    ],
    "2. å †ç–Šèˆ‡ä½‡åˆ— (Stacks & Queues)": [
        "Stack", "å †ç–Š", "Queue", "ä½‡åˆ—", "Circular Queue", "ç’°ç‹€ä½‡åˆ—", "Priority Queue", "å„ªå…ˆä½‡åˆ—"
    ],
    "3. æ¨¹ (Trees)": [
        "Binary Tree", "äºŒå…ƒæ¨¹", "Binary Search Tree", "äºŒå…ƒæœå°‹æ¨¹", "BST", 
        "AVL", "Heap", "å †ç©", "B-Tree", "B Tree", "B+ Tree", "Red-Black", "ç´…é»‘æ¨¹",
        "Traversal", "è¿½è¹¤", "Inorder", "Preorder", "Postorder", "Spanning Tree", "ç”Ÿæˆæ¨¹"
    ],
    "4. åœ–å½¢ (Graphs)": [
        "Graph", "åœ–å½¢", "DFS", "BFS", "Depth First", "Breadth First", 
        "Shortest Path", "æœ€çŸ­è·¯å¾‘", "Dijkstra", "Floyd", "Prim", "Kruskal", 
        "Adjacency Matrix", "é„°æ¥çŸ©é™£", "Adjacency List", "é„°æ¥ä¸²åˆ—", "Topological", "æ‹“æ’²"
    ],
    "5. æ’åº (Sorting)": [
        "Sorting", "æ’åº", "Quick Sort", "å¿«é€Ÿæ’åº", "Merge Sort", "åˆä½µæ’åº", 
        "Heap Sort", "å †ç©æ’åº", "Bubble Sort", "æ°£æ³¡æ’åº", "Insertion Sort", "æ’å…¥æ’åº",
        "Selection Sort", "é¸æ“‡æ’åº", "Shell Sort", "å¸Œçˆ¾æ’åº", "Radix Sort", "åŸºæ•¸æ’åº"
    ],
    "6. æœå°‹èˆ‡é›œæ¹Š (Searching & Hashing)": [
        "Search", "æœå°‹", "Binary Search", "äºŒåˆ†æœå°‹", "Hashing", "Hash", "é›œæ¹Š", 
        "Collision", "ç¢°æ’", "Probing", "æ¢æ¸¬"
    ],
    "7. æ¼”ç®—æ³•åˆ†æ (Algorithm Analysis)": [
        "Big O", "Time Complexity", "æ™‚é–“è¤‡é›œåº¦", "Space Complexity", "ç©ºé–“è¤‡é›œåº¦", 
        "Recursion", "éè¿´", "Recurrence", "éè¿´é—œä¿‚", "Dynamic Programming", "å‹•æ…‹è¦åŠƒ"
    ]
}

# 2. Specific Sub-topics (Granular DS)
SPECIFIC_TOPICS = {
    "äºŒå…ƒæ¨¹ (Binary Tree)": ["Binary Tree", "äºŒå…ƒæ¨¹"],
    "äºŒå…ƒæœå°‹æ¨¹ (BST)": ["Binary Search Tree", "äºŒå…ƒæœå°‹æ¨¹", "BST"],
    "å †ç© (Heap)": ["Heap", "å †ç©"],
    "AVLæ¨¹ (AVL Tree)": ["AVL"],
    "B-Tree / B+ Tree": ["B-Tree", "B Tree", "B+ Tree"],
    "ç´…é»‘æ¨¹ (Red-Black Tree)": ["Red-Black", "ç´…é»‘æ¨¹"],
    "æ¨¹çš„è¿½è¹¤ (Tree Traversal)": ["Traversal", "è¿½è¹¤", "Inorder", "Preorder", "Postorder"],
    "æœ€å°ç”Ÿæˆæ¨¹ (MST)": ["Spanning Tree", "ç”Ÿæˆæ¨¹", "Prim", "Kruskal"],
    "æœ€çŸ­è·¯å¾‘ (Shortest Path)": ["Shortest Path", "æœ€çŸ­è·¯å¾‘", "Dijkstra", "Floyd"],
    "æ·±åº¦/å»£åº¦å„ªå…ˆæœå°‹ (DFS/BFS)": ["DFS", "BFS", "Depth First", "Breadth First"],
    "å¿«é€Ÿæ’åº (Quick Sort)": ["Quick Sort", "å¿«é€Ÿæ’åº"],
    "åˆä½µæ’åº (Merge Sort)": ["Merge Sort", "åˆä½µæ’åº"],
    "å †ç©æ’åº (Heap Sort)": ["Heap Sort", "å †ç©æ’åº"],
    "é›œæ¹Šè¡¨ (Hash Table)": ["Hashing", "Hash", "é›œæ¹Š"],
    "äºŒåˆ†æœå°‹ (Binary Search)": ["Binary Search", "äºŒåˆ†æœå°‹"],
    "æ™‚é–“è¤‡é›œåº¦ (Time Complexity)": ["Big O", "Time Complexity", "æ™‚é–“è¤‡é›œåº¦"],
    "éè¿´ (Recursion)": ["Recursion", "éè¿´"]
}

# 3. Emerging / Other Topics (New!)
EMERGING_TOPICS = {
    "è³‡è¨Šå®‰å…¨ (Security)": ["Security", "è³‡å®‰", "Encryption", "åŠ å¯†", "Decryption", "è§£å¯†", "RSA", "AES", "Signature", "ç°½ç« ", "Hacking", "é§­å®¢", "Malware", "æƒ¡æ„ç¨‹å¼", "Phishing", "é‡£é­š"],
    "äººå·¥æ™ºæ…§ (AI/ML)": ["AI", "Artificial Intelligence", "äººå·¥æ™ºæ…§", "Machine Learning", "æ©Ÿå™¨å­¸ç¿’", "Deep Learning", "æ·±åº¦å­¸ç¿’", "Neural Network", "é¡ç¥ç¶“ç¶²è·¯", "CNN", "RNN", "Transformer", "LLM"],
    "è³‡æ–™åº« (Database)": ["Database", "è³‡æ–™åº«", "SQL", "Normalization", "æ­£è¦åŒ–", "Transaction", "äº¤æ˜“", "ACID", "Index", "ç´¢å¼•", "B+ Tree"],
    "ç¶²è·¯ (Network)": ["Network", "ç¶²è·¯", "TCP", "IP", "OSI", "Protocol", "å”å®š", "HTTP", "Socket"],
    "ä½œæ¥­ç³»çµ± (OS)": ["Operating System", "ä½œæ¥­ç³»çµ±", "Process", "è¡Œç¨‹", "Thread", "åŸ·è¡Œç·’", "Deadlock", "æ­»çµ", "Scheduling", "æ’ç¨‹", "Memory Management", "è¨˜æ†¶é«”ç®¡ç†", "Paging", "åˆ†é "]
}

def get_year_from_filename(filename):
    # Extract year (e.g., "114å¹´..." -> 114, "1 1 3å¹´..." -> 113)
    # Handle spaces in year like "1 1 3"
    clean_name = filename.replace(" ", "")
    match = re.search(r'(\d{3})å¹´', clean_name)
    if match:
        return int(match.group(1))
    return 0

def analyze_subset(files, subset_name):
    category_counts = defaultdict(int)
    specific_counts = defaultdict(int)
    emerging_counts = defaultdict(int)
    
    print(f"Analyzing subset: {subset_name} ({len(files)} files)...")

    for filename in files:
        filepath = os.path.join(PROCESSED_DIR, filename)
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read().lower()
            
            # 1. DS Categories
            for category, terms in CATEGORIES.items():
                count = 0
                for term in terms:
                    count += content.count(term.lower())
                if count > 0:
                    category_counts[category] += count
            
            # 2. DS Specific
            for topic, terms in SPECIFIC_TOPICS.items():
                count = 0
                for term in terms:
                    count += content.count(term.lower())
                if count > 0:
                    specific_counts[topic] += count
            
            # 3. Emerging
            for topic, terms in EMERGING_TOPICS.items():
                count = 0
                for term in terms:
                    count += content.count(term.lower())
                if count > 0:
                    emerging_counts[topic] += count
                    
        except Exception as e:
            print(f"Error reading {filename}: {e}")
            
    return category_counts, specific_counts, emerging_counts

def generate_trend_report(results):
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("# æ­·å±†è€ƒé¡Œè¶¨å‹¢åˆ†æå ±å‘Š (112-114å¹´ vs å…¨éƒ¨)\n\n")
        
        # 1. Emerging Topics Analysis
        f.write("## ğŸš€ æ–°èˆˆèˆ‡è·¨é ˜åŸŸä¸»é¡Œåˆ†æ\n")
        f.write("é™¤äº†è³‡æ–™çµæ§‹ï¼Œæˆ‘å€‘ä¹Ÿæƒæäº†è³‡å®‰ã€AIã€è³‡æ–™åº«ç­‰ä¸»é¡Œã€‚\n\n")
        
        emerging_recent = results['recent']['emerging']
        emerging_114 = results['114']['emerging']
        
        f.write("| ä¸»é¡Œ | è¿‘ä¸‰å¹´ (112-114) å‡ºç¾æ¬¡æ•¸ | 114å¹´ å‡ºç¾æ¬¡æ•¸ |\n")
        f.write("| :--- | :---: | :---: |\n")
        
        sorted_emerging = sorted(EMERGING_TOPICS.keys())
        for topic in sorted_emerging:
            count_recent = emerging_recent.get(topic, 0)
            count_114 = emerging_114.get(topic, 0)
            f.write(f"| {topic} | {count_recent} | {count_114} |\n")
        f.write("\n---\n\n")

        # 2. DS Trend Comparison
        f.write("## ğŸ“ˆ è³‡æ–™çµæ§‹è€ƒé»è¶¨å‹¢æ¯”è¼ƒ\n")
        f.write("æ¯”è¼ƒã€Œè¿‘ä¸‰å¹´ã€èˆ‡ã€Œæ­·å¹´ã€çš„ç†±é–€è€ƒé»å·®ç•°ã€‚\n\n")
        
        f.write("| æ’å | æ­·å¹´ç†±é–€ (All) | è¿‘ä¸‰å¹´ç†±é–€ (112-114) | 114å¹´ç†±é–€ |\n")
        f.write("| :--- | :--- | :--- | :--- |\n")
        
        # Get top 5 specific topics for each subset
        def get_top_k(counts, k=5):
            return sorted(counts.items(), key=lambda x: x[1], reverse=True)[:k]
            
        top_all = get_top_k(results['all']['specific'])
        top_recent = get_top_k(results['recent']['specific'])
        top_114 = get_top_k(results['114']['specific'])
        
        for i in range(5):
            row = f"| {i+1} | "
            row += f"{top_all[i][0]} ({top_all[i][1]}) | " if i < len(top_all) else " - | "
            row += f"{top_recent[i][0]} ({top_recent[i][1]}) | " if i < len(top_recent) else " - | "
            row += f"{top_114[i][0]} ({top_114[i][1]}) |" if i < len(top_114) else " - |"
            f.write(row + "\n")
            
        f.write("\n---\n\n")
        
        # 3. Detailed 114 Analysis
        f.write("## ğŸ¯ 114å¹´è€ƒé¡Œé‡é»åˆ†æ\n")
        f.write("é‡å°ä»Šå¹´åº¦ (114) çš„è€ƒé¡Œé€²è¡Œç´°éƒ¨åˆ†è§£ã€‚\n\n")
        
        f.write("### è³‡æ–™çµæ§‹åˆ†ä½ˆ\n")
        sorted_114_cats = sorted(results['114']['categories'].items(), key=lambda x: x[1], reverse=True)
        for cat, count in sorted_114_cats:
            if count > 0:
                f.write(f"- **{cat}**: {count} æ¬¡\n")
        
        f.write("\n### ç´°é …è€ƒé»\n")
        sorted_114_spec = sorted(results['114']['specific'].items(), key=lambda x: x[1], reverse=True)
        for topic, count in sorted_114_spec:
            if count > 0:
                f.write(f"- {topic}: {count} æ¬¡\n")

    print(f"Trend analysis complete. Report generated at {OUTPUT_FILE}")

def main():
    if not os.path.exists(PROCESSED_DIR):
        print(f"Directory {PROCESSED_DIR} not found.")
        return

    all_files = [f for f in os.listdir(PROCESSED_DIR) if f.endswith(".txt")]
    
    # Filter files
    recent_files = [f for f in all_files if get_year_from_filename(f) in [112, 113, 114]]
    files_114 = [f for f in all_files if get_year_from_filename(f) == 114]
    
    results = {}
    
    # Run analysis
    c_all, s_all, e_all = analyze_subset(all_files, "All Years")
    results['all'] = {'categories': c_all, 'specific': s_all, 'emerging': e_all}
    
    c_recent, s_recent, e_recent = analyze_subset(recent_files, "Recent (112-114)")
    results['recent'] = {'categories': c_recent, 'specific': s_recent, 'emerging': e_recent}
    
    c_114, s_114, e_114 = analyze_subset(files_114, "114 Only")
    results['114'] = {'categories': c_114, 'specific': s_114, 'emerging': e_114}
    
    generate_trend_report(results)

if __name__ == "__main__":
    main()
